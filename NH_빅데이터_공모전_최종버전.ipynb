{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNkdGY-6RWyi"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리 설치 및 import\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import distance\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KRX 한국 주식 정보 엑셀파일 불러오기\n",
        "file = pd.read_excel('/content/data_3741_20230913.xlsx')\n",
        "df = pd.DataFrame(file)\n",
        "code_num = df['단축코드'] # 종목 별 고유코드"
      ],
      "metadata": {
        "id": "2q9uhUTHSMj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹크롤링을 이용한 한국 주식 종목 별 카테고리 산정\n",
        "category_kor = list()\n",
        "\n",
        "for i in range(len(code_num)):\n",
        "  code = code_num[i]\n",
        "  specific_options = webdriver.ChromeOptions()\n",
        "  specific_options.add_argument('--headless')\n",
        "  specific_options.add_argument('--no-sandbox')\n",
        "  driver = webdriver.Chrome(options = specific_options)\n",
        "  driver.get('https://finance.naver.com/item/main.naver?code='+code)\n",
        "\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  program = soup.find_all(class_ = 'h_sub sub_tit7')\n",
        "  category = list()\n",
        "\n",
        "  for j in program:\n",
        "    j = j.text\n",
        "    j = j.strip()\n",
        "    category.append(j)\n",
        "\n",
        "  if category == []:\n",
        "    category_kor.append(\"NONE\")\n",
        "  else:\n",
        "    category_after = category[0].split(':')\n",
        "    category_after_2 = category_after[1].split('｜')\n",
        "    category_after_3 = category_after_2[0].replace(\" \",\"\")\n",
        "    category_kor.append(category_after_3)\n",
        "\n",
        "category_kor = pd.DataFrame(category_kor)"
      ],
      "metadata": {
        "id": "aHbIu8goRx-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 산출한 한국 주식 종목들의 카테고리를 엑셀로 저장\n",
        "category_kor.to_excel(\"category_kor.xlsx\")"
      ],
      "metadata": {
        "id": "gIoocgf4ar-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미국 주식 정보 엑셀파일 불러오기\n",
        "file_2 = pd.read_excel('/content/NASDAQ_FC_STK_IEM_IFO.xlsx')\n",
        "df_2 = pd.DataFrame(file_2)\n",
        "code_num_2 = df_2['tck_iem_cd'] # 종목 별 고유코드"
      ],
      "metadata": {
        "id": "MSHigRFSAsUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹크롤링을 이용한 미국 주식 종목 별 카테고리 산정\n",
        "category_us = list()\n",
        "\n",
        "for i in range(len(code_num_2)):\n",
        "  code = code_num_2[i].replace(\" \",\"\")\n",
        "  code = code.upper()\n",
        "  specific_options = webdriver.ChromeOptions()\n",
        "  specific_options.add_argument('--headless')\n",
        "  specific_options.add_argument('--no-sandbox')\n",
        "  driver = webdriver.Chrome(options = specific_options)\n",
        "  driver.get('https://m.stock.naver.com/worldstock/stock/'+code+'.O/total')\n",
        "  url = 'https://m.stock.naver.com/worldstock/stock/'+code+'.O/total'\n",
        "  time.sleep(1)\n",
        "\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  program = soup.find_all(class_ = 'StockInfo_value__3l7zZ')\n",
        "  category = list()\n",
        "\n",
        "  for i in program:\n",
        "    i = i.text\n",
        "    i = i.strip()\n",
        "    category.append(i)\n",
        "\n",
        "  if category == []:\n",
        "    category_us.append(\"NONE\")\n",
        "  else:\n",
        "    category = category[7]\n",
        "    category_us.append(category)\n",
        "\n",
        "category_us = pd.DataFrame(category_us)\n",
        "category_us.to_excel(\"category_us.xlsx\") # 산출한 미국 주식 종목들의 카테고리를 엑셀로 저장"
      ],
      "metadata": {
        "id": "biHFvdHdsEgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국 주식 종목들의 카테고리 불러오기\n",
        "file_3 = pd.read_excel('/content/category_kor.xlsx')\n",
        "df_3 = pd.DataFrame(file_3)\n",
        "code_num_3 = df_3[0]\n",
        "\n",
        "# 미국 주식 종목들의 카테고리 불러오기\n",
        "file_4 = pd.read_excel('/content/category_us.xlsx')\n",
        "df_4 = pd.DataFrame(file_4)\n",
        "code_num_4 = df_4[0]\n",
        "\n",
        "# 한국 주식 종목 중복 제거\n",
        "category_kor_edit = list()\n",
        "for i in code_num_3:\n",
        "  if i not in category_kor_edit:\n",
        "    category_kor_edit.append(i)\n",
        "\n",
        "# 미국 주식 종목 중복 제거\n",
        "category_us_edit = list()\n",
        "for j in code_num_4:\n",
        "  if j not in category_us_edit:\n",
        "    category_us_edit.append(j)"
      ],
      "metadata": {
        "id": "MfTl-5jVPXCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국, 미국 주식 종목들의 업종 엑셀로 저장 (이후 분석에 사용할 업종 15개 채택)\n",
        "pd.DataFrame(category_kor_edit).to_excel(\"category_kor_edit.xlsx\")\n",
        "pd.DataFrame(category_us_edit).to_excel(\"category_us_edit.xlsx\")"
      ],
      "metadata": {
        "id": "M5ESLoCuRBqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택한 15개의 업종에 해당하는 한국 주식 종목 추출\n",
        "file_5 = pd.read_excel('/content/국내주식.xlsx') # data_3741_20230913.xlsx 파일과 웹크롤링을 통해 얻은 종목정보(category_kor_edit.xlsx)를 엑셀을 통해 연결한 파일 ([업종] 칼럼을 추가했음.)\n",
        "df_5 = pd.DataFrame(file_5)\n",
        "df_kor = df_5[['단축코드', '업종', '한글 종목명']]\n",
        "\n",
        "condition_1 = ((df_5['업종'] == '건설') | (df_5['업종'] == '담배') | (df_5['업종'] == '방송과엔터테인먼트') |\n",
        "               (df_5['업종'] == '백화점과일반상점') | (df_5['업종'] == '사무용전자제품') | (df_5['업종'] == '손해보험') |\n",
        "               (df_5['업종'] == '식품과기본식료품소매') | (df_5['업종'] == '우주항공과국방') | (df_5['업종'] == '은행') |\n",
        "               (df_5['업종'] == '자동차') | (df_5['업종'] == '전자장비와기기') | (df_5['업종'] == '제약') |\n",
        "               (df_5['업종'] == '철강') | (df_5['업종'] == '컴퓨터와주변기기') | (df_5['업종'] == '항공사'))\n",
        "\n",
        "df_kor = df_kor.loc[condition_1]"
      ],
      "metadata": {
        "id": "v7MMnPSodrCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국 종목 별 시가총액 웹크롤링\n",
        "df_kor_code = list(df_kor['단축코드'])\n",
        "category_kor_price = list()\n",
        "\n",
        "for i in range(len(df_kor_code)):\n",
        "  code = df_kor_code[i]\n",
        "  specific_options = webdriver.ChromeOptions()\n",
        "  specific_options.add_argument('--headless')\n",
        "  specific_options.add_argument('--no-sandbox')\n",
        "  driver = webdriver.Chrome(options = specific_options)\n",
        "  driver.get('https://finance.naver.com/item/main.naver?code='+code)\n",
        "\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  program = soup.find_all(class_ = 'strong')\n",
        "  category = list()\n",
        "\n",
        "  for j in program:\n",
        "    j = j.text\n",
        "    j = j.strip()\n",
        "    category.append(j)\n",
        "\n",
        "  price = category[0]\n",
        "  price_2 = price.replace(\" \", \"\")\n",
        "  price_3 = price_2.replace(\"\\n\", \"\")\n",
        "  price_4 = price_3.replace(\"\\t\", \"\")\n",
        "  price_5 = price_4.replace(\"시가총액\", \"\")\n",
        "  price_6 = price_5.replace(\"원\", \"\")\n",
        "  price_7 = price_6.replace(\",\", \"\")\n",
        "\n",
        "  a = price_7.find(\"조\")\n",
        "  b = price_7.find(\"억\")\n",
        "  c = price_7.find(\"만\")\n",
        "\n",
        "  if a != -1:\n",
        "    if b != -1:\n",
        "      if c != -1:\n",
        "        price_total = int(price_7[:a]) * 1000000000000 + int(price_7[a+1:b]) * 100000000 + int(price_7[b+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_7[:a]) * 1000000000000 + int(price_7[a+1:b]) * 100000000\n",
        "    else:\n",
        "      if c != -1:\n",
        "        price_total = int(price_7[:a]) * 1000000000000 + int(price_7[a+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_7[:a]) * 1000000000000\n",
        "  else:\n",
        "    if b != -1:\n",
        "      if c != -1:\n",
        "        price_total = int(price_7[:b]) * 100000000 + int(price_7[b+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_7[:b]) * 100000000\n",
        "    else:\n",
        "      if c != -1:\n",
        "        price_total = int(price_7[:c]) * 10000\n",
        "      else:\n",
        "        price_total = 0\n",
        "\n",
        "  category_kor_price.append(price_total)"
      ],
      "metadata": {
        "id": "PTNCf4MAd8Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임에 시가총액 추가 및 정렬\n",
        "df_kor['시가총액'] = category_kor_price\n",
        "df_kor = df_kor.sort_values(by = ['업종', '시가총액'], ascending = [True, False])\n",
        "\n",
        "df_kor.to_excel(\"국내업종및시가총액.xlsx\") # 한국 주식 종목 엑셀로 저장"
      ],
      "metadata": {
        "id": "9GxuNlPsqUaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택한 15개의 업종에 속해있는 미국 주식 추출\n",
        "file_6 = pd.read_excel('/content/해외주식.xlsx') # content/NASDAQ_FC_STK_IEM_IFO.xlsx 파일과 웹크롤링을 통해 얻은 종목정보(category_us_edit.xlsx)를 엑셀을 통해 연결한 파일 ([업종] 칼럼을 추가했음.)\n",
        "df_6 = pd.DataFrame(file_6)\n",
        "df_us = df_6[['tck_iem_cd', '업종', 'fc_sec_eng_nm']]\n",
        "\n",
        "condition_2 = ((df_6['업종'] == '건설 및 엔지니어링') | (df_6['업종'] == '담배') | (df_6['업종'] == '방송') |\n",
        "               (df_6['업종'] == '백화점') | (df_6['업종'] == '사무기기') | (df_6['업종'] == '손해보험') |\n",
        "               (df_6['업종'] == '식품 소매 및 유통') | (df_6['업종'] == '항공우주 및 방위') | (df_6['업종'] == '은행') |\n",
        "               (df_6['업종'] == '자동차 및 트럭 제조') | (df_6['업종'] == '전자 장비 및 부품') | (df_6['업종'] == '제약') |\n",
        "               (df_6['업종'] == '철 및 강철') | (df_6['업종'] == '컴퓨터 하드웨어') | (df_6['업종'] == '항공사'))\n",
        "\n",
        "df_us = df_us.loc[condition_2]"
      ],
      "metadata": {
        "id": "VZMUTkwIrIjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미국 종목 별 시가총액 웹크롤링\n",
        "df_us_code = list(df_us['tck_iem_cd'])\n",
        "category_us_price = list()\n",
        "\n",
        "for i in range(len(df_us_code)):\n",
        "  code = df_us_code[i].replace(\" \",\"\")\n",
        "  code = code.upper()\n",
        "  specific_options = webdriver.ChromeOptions()\n",
        "  specific_options.add_argument('--headless')\n",
        "  specific_options.add_argument('--no-sandbox')\n",
        "  driver = webdriver.Chrome(options = specific_options)\n",
        "  driver.get('https://m.stock.naver.com/worldstock/stock/'+code+'.O/total')\n",
        "  url = 'https://m.stock.naver.com/worldstock/stock/'+code+'.O/total'\n",
        "  time.sleep(1)\n",
        "\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  program = soup.find_all(class_ = 'StockInfo_valueDesc__1uIaD')\n",
        "  category = list()\n",
        "\n",
        "  for i in program:\n",
        "    i = i.text\n",
        "    i = i.strip()\n",
        "    category.append(i)\n",
        "\n",
        "  if category != []:\n",
        "    price = category[0]\n",
        "    price_2 = price.replace(\" \", \"\")\n",
        "    price_3 = price_2.replace(\"\\n\", \"\")\n",
        "    price_4 = price_3.replace(\"\\t\", \"\")\n",
        "    price_5 = price_4.replace(\"시가총액\", \"\")\n",
        "    price_6 = price_5.replace(\"원\", \"\")\n",
        "    price_7 = price_6.replace(\",\", \"\")\n",
        "    price_8 = price_7.replace(\".\", \"\")\n",
        "\n",
        "    a = price_8.find(\"조\")\n",
        "    b = price_8.find(\"억\")\n",
        "    c = price_8.find(\"만\")\n",
        "  else:\n",
        "    price_8 = '0'\n",
        "    a = -1\n",
        "    b = -1\n",
        "    c = -1\n",
        "\n",
        "  if a != -1:\n",
        "    if b != -1:\n",
        "      if c != -1:\n",
        "        price_total = int(price_8[:a]) * 1000000000000 + int(price_8[a+1:b]) * 100000000 + int(price_8[b+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_8[:a]) * 1000000000000 + int(price_8[a+1:b]) * 100000000\n",
        "    else:\n",
        "      if c != -1:\n",
        "        price_total = int(price_8[:a]) * 1000000000000 + int(price_8[a+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_8[:a]) * 1000000000000\n",
        "  else:\n",
        "    if b != -1:\n",
        "      if c != -1:\n",
        "        price_total = int(price_8[:b]) * 100000000 + int(price_8[b+1:c]) * 10000\n",
        "      else:\n",
        "        price_total = int(price_8[:b]) * 100000000\n",
        "    else:\n",
        "      if c != -1:\n",
        "        price_total = int(price_8[:c]) * 10000\n",
        "      else:\n",
        "        price_total = 0\n",
        "\n",
        "  category_us_price.append(price_total)"
      ],
      "metadata": {
        "id": "HMOruRoatQLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임에 시가총액 추가\n",
        "df_us['시가총액'] = category_us_price\n",
        "df_us = df_us.sort_values(by = ['업종', '시가총액'], ascending = [True, False])\n",
        "df_us.to_excel(\"해외업종및시가총액.xlsx\") # 미국 주식 종목 엑셀로 저장"
      ],
      "metadata": {
        "id": "R7WXB2J0643v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 국내 주식의 일자별 주가 정보 불러오기 및 통합\n",
        "data_before = pd.read_excel('/content/20230103.xlsx') # KRX 제공 전종목 시세 (2023년 1월 3일 기준)\n",
        "data_after = pd.DataFrame(data_before)\n",
        "data_after['일자'] = '20230103'\n",
        "\n",
        "date_list = ['20230104','20230105','20230106','20230109','20230110','20230111','20230112','20230113','20230116','20230117','20230118',\n",
        "             '20230119','20230120','20230125','20230126','20230127','20230130','20230131','20230201','20230202','20230203','20230206',\n",
        "             '20230207','20230208','20230209','20230210','20230213','20230214','20230215','20230216','20230217','20230220','20230221',\n",
        "             '20230222','20230223','20230224','20230227','20230228','20230302','20230303','20230306','20230307','20230308','20230309',\n",
        "             '20230310','20230313','20230314','20230315','20230316','20230317','20230320','20230321','20230322','20230323','20230324',\n",
        "             '20230327','20230328','20230329','20230330','20230331','20230403','20230404','20230405','20230406','20230407','20230410',\n",
        "             '20230411','20230412','20230413','20230414','20230417','20230418','20230419','20230420','20230421','20230424','20230425',\n",
        "             '20230426','20230427','20230428','20230502','20230503','20230504','20230508','20230509','20230510','20230511','20230512',\n",
        "             '20230515','20230516','20230517','20230518','20230519','20230522','20230523','20230524','20230525','20230526','20230530',\n",
        "             '20230531','20230601','20230602','20230605','20230607','20230608','20230609','20230612','20230613','20230614','20230615',\n",
        "             '20230616','20230619','20230620','20230621','20230622','20230623','20230626','20230627','20230628','20230629','20230630',\n",
        "             '20230703','20230704','20230705','20230706','20230707','20230710','20230711','20230712','20230713','20230714','20230717',\n",
        "             '20230718','20230719','20230720','20230721','20230724','20230725','20230726','20230727','20230728','20230731','20230801',\n",
        "             '20230802','20230803','20230804','20230807','20230808','20230809','20230810','20230811','20230814','20230816','20230817',\n",
        "             '20230818','20230821','20230822','20230823','20230824','20230825','20230828','20230829','20230830','20230831']\n",
        "\n",
        "data_list_len = len(date_list)\n",
        "\n",
        "# KRX 제공 전종목 시세 데이터 (2023년 1월 3일 ~ 2023년 8월 31일) [일자] 칼럼 생성 및 모두 통합\n",
        "for i in range(data_list_len):\n",
        "  date = date_list[i]\n",
        "  data_before_2 = pd.read_excel('/content/'+date+'.xlsx')\n",
        "  data_after_2 = pd.DataFrame(data_before_2)\n",
        "  data_after_2['일자'] = date\n",
        "  data_after = pd.concat([data_after, data_after_2])\n",
        "\n",
        "data_after.to_excel('data_integrated.xlsx')"
      ],
      "metadata": {
        "id": "lEj-pM36EIxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_list_kor = ['20230104','20230105','20230106','20230109','20230110','20230111','20230112','20230113','20230116','20230117','20230118',\n",
        "             '20230119','20230120','20230125','20230126','20230127','20230130','20230131','20230201','20230202','20230203','20230206',\n",
        "             '20230207','20230208','20230209','20230210','20230213','20230214','20230215','20230216','20230217','20230220','20230221',\n",
        "             '20230222','20230223','20230224','20230227','20230228','20230302','20230303','20230306','20230307','20230308','20230309',\n",
        "             '20230310','20230313','20230314','20230315','20230316','20230317','20230320','20230321','20230322','20230323','20230324',\n",
        "             '20230327','20230328','20230329','20230330','20230331','20230403','20230404','20230405','20230406','20230407','20230410',\n",
        "             '20230411','20230412','20230413','20230414','20230417','20230418','20230419','20230420','20230421','20230424','20230425',\n",
        "             '20230426','20230427','20230428','20230502','20230503','20230504','20230508','20230509','20230510','20230511','20230512',\n",
        "             '20230515','20230516','20230517','20230518','20230519','20230522','20230523','20230524','20230525','20230526','20230530',\n",
        "             '20230531','20230601','20230602','20230605','20230607','20230608','20230609','20230612','20230613','20230614','20230615',\n",
        "             '20230616','20230619','20230620','20230621','20230622','20230623','20230626','20230627','20230628','20230629','20230630',\n",
        "             '20230703','20230704','20230705','20230706','20230707','20230710','20230711','20230712','20230713','20230714','20230717',\n",
        "             '20230718','20230719','20230720','20230721','20230724','20230725','20230726','20230727','20230728','20230731','20230801',\n",
        "             '20230802','20230803','20230804','20230807','20230808','20230809','20230810','20230811','20230814','20230816','20230817',\n",
        "             '20230818','20230821','20230822','20230823','20230824','20230825','20230828','20230829','20230830','20230831']\n",
        "\n",
        "date_list_us = ['20230103','20230104','20230105','20230108','20230109','20230110','20230111','20230112','20230115','20230116','20230117',\n",
        "             '20230118','20230119','20230124','20230125','20230126','20230129','20230130','20230131','20230201','20230202','20230205',\n",
        "             '20230206','20230207','20230208','20230209','20230212','20230213','20230214','20230215','20230216','20230219','20230220',\n",
        "             '20230221','20230222','20230223','20230226','20230227','20230301','20230302','20230305','20230306','20230307','20230308',\n",
        "             '20230309','20230312','20230313','20230314','20230315','20230316','20230319','20230320','20230321','20230322','20230323',\n",
        "             '20230326','20230327','20230328','20230329','20230330','20230402','20230403','20230404','20230405','20230406','20230409',\n",
        "             '20230410','20230411','20230412','20230413','20230416','20230417','20230418','20230419','20230420','20230423','20230424',\n",
        "             '20230425','20230426','20230427','20230501','20230502','20230503','20230507','20230508','20230509','20230510','20230511',\n",
        "             '20230514','20230515','20230516','20230517','20230518','20230521','20230522','20230523','20230524','20230525','20230529',\n",
        "             '20230530','20230531','20230601','20230604','20230606','20230607','20230608','20230611','20230612','20230613','20230614',\n",
        "             '20230615','20230618','20230619','20230620','20230621','20230622','20230625','20230626','20230627','20230628','20230629',\n",
        "             '20230702','20230703','20230704','20230705','20230706','20230709','20230710','20230711','20230712','20230713','20230716',\n",
        "             '20230717','20230718','20230719','20230720','20230723','20230724','20230725','20230726','20230727','20230730','20230731',\n",
        "             '20230801','20230802','20230803','20230806','20230807','20230808','20230809','20230810','20230813','20230815','20230816',\n",
        "             '20230817','20230820','20230821','20230822','20230823','20230824','20230827','20230828','20230829','20230830']\n"
      ],
      "metadata": {
        "id": "LhEuuEE1o77Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 일자까지 통합한 한국 및 미국 주식 정보 엑셀파일 불러오기\n",
        "file_kor = pd.read_excel('/content/국내종목정리.xlsx',dtype = \"str\") # 해외업종및시가총액.xlsx 파일에 [20230103] ~ [20230831] 칼럼을 엑셀을 통해 추가, 이때 각 셀의 값은 0으로 지정\n",
        "file_us = pd.read_excel('/content/해외종목정리.xlsx' ,dtype = \"str\") # 국내업종및시가총액.xlsx 파일에 [20230103] ~ [20230831] 칼럼을 엑셀을 통해 추가, 이때 각 셀의 값은 0으로 지정\n",
        "file_kor_p = pd.read_excel('/content/국내주식통합.xlsx' ,dtype = \"str\") # data_integrated.xlsx 파일명을 국내주식통합으로 변경 후 사용\n",
        "file_us_p = pd.read_excel('/content/해외주식통합.xlsx' ,dtype = \"str\") # NASDAQ_DT_FC_STK_QUT.xlsx 파일명을 해외주식통합으로 변경 후 사용\n",
        "\n",
        "data_kor = pd.DataFrame(file_kor)\n",
        "data_us = pd.DataFrame(file_us)\n",
        "data_kor_p = pd.DataFrame(file_kor_p)\n",
        "data_us_p = pd.DataFrame(file_us_p)"
      ],
      "metadata": {
        "id": "7oGBRTeqvWrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국 주식 종목 별 등락 전처리\n",
        "for i in date_list_kor:\n",
        "  for j in list(data_kor['단축코드']):\n",
        "    condition = (data_kor_p['일자'] == i)\n",
        "    condition_2 = (data_kor_p['종목코드'] == j)\n",
        "    condition_3 = (data_kor['단축코드'] == j)\n",
        "    condition_total = (condition & condition_2)\n",
        "    sep = data_kor_p.loc[condition_total]\n",
        "    dif = 0\n",
        "    dif = int(sep['종가'].iloc[0]) - int(sep['시가'].iloc[0])\n",
        "    data_kor.loc[condition_3]\n",
        "    if dif > 0:\n",
        "      data_kor.loc[condition_3, int(i)]= 1\n",
        "    elif dif == 0:\n",
        "      data_kor.loc[condition_3, int(i)] = 0\n",
        "    elif dif < 0:\n",
        "      data_kor.loc[condition_3, int(i)] = -1"
      ],
      "metadata": {
        "id": "tSQ06Jd3yz9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리한 데이터 엑셀로 저장\n",
        "data_kor.to_excel(\"국내최종본.xlsx\")"
      ],
      "metadata": {
        "id": "P-ZRTJ9tRCz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미국 주식 종목 별 등락 전처리\n",
        "for i in date_list_us:\n",
        "  for j in list(data_us['단축코드']):\n",
        "    condition = (data_us_p['trd_dt'] == i)\n",
        "    condition_2 = (data_us_p['tck_iem_cd'] == j.replace(\" \",\"\"))\n",
        "    condition_3 = (data_us['단축코드'] == j)\n",
        "    condition_total = (condition & condition_2)\n",
        "    sep = data_us_p.loc[condition_total]\n",
        "    if sep.empty == False:\n",
        "      dif = float(sep['gts_iem_end_pr'].iloc[0]) - float(sep['gts_iem_ong_pr'].iloc[0])\n",
        "      data_us.loc[condition_3]\n",
        "      if dif > 0:\n",
        "        data_us.loc[condition_3, int(i)] = 1\n",
        "        print(1)\n",
        "      elif dif == 0:\n",
        "        data_us.loc[condition_3, int(i)] = 0\n",
        "        print(2)\n",
        "      elif dif < 0:\n",
        "        data_us.loc[condition_3, int(i)] = -1\n",
        "        print(3)\n",
        "    else:\n",
        "      data_us.loc[condition_3, int(i)] = 'NONE'"
      ],
      "metadata": {
        "id": "wvizr4Qzch1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리한 데이터 엑셀로 저장\n",
        "data_us.to_excel(\"해외최종본.xlsx\")"
      ],
      "metadata": {
        "id": "JhQ-b-fyycoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이후 엑셀을 통해 업종에 대해 부분합을 진행하여 일자 별 평균 등락 데이터를 구함. (국내최종본.xlsx과 해외최종본.xlsx에 대하여 모두 진행, 총 row의 개수 15개.)\n",
        "# 하루 일자 차이를 두고 비교하기 위해 국내최종본에서 [20230103] 칼럼 삭제\n",
        "# 이후 국내최종본.xlsx과 해외최종본.xlsx에서 특정 일자에 하나라도 빈 셀이나 NONE 값이 있다면 해당 칼럼 각 파일에서 모두 삭제\n",
        "# ex) 해외최종본.xlsx의 [20230108] 칼럼과 국내최종본.xlsx의 [20230109] 칼럼 삭제\n",
        "# 모두 진행 후 등락정규화국내.xlsx과 등락정규화해외.xlsx로 파일명 변경"
      ],
      "metadata": {
        "id": "H3h9Qmpq6B4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 업종 별 등락 시계열 비교 그래프\n",
        "file_n_kor = pd.read_excel('/content/등락정규화국내.xlsx')\n",
        "file_n_us = pd.read_excel('/content/등락정규화해외.xlsx')\n",
        "data_n_kor = pd.DataFrame(file_n_kor)\n",
        "data_n_us = pd.DataFrame(file_n_us)\n",
        "\n",
        "category_list_kor = ['건설', '담배', '방송과엔터테인먼트', '백화점과일반상점', '사무용전자제품', '손해보험', '식품과기본식료품소매',\n",
        "                     '우주항공과국방', '은행', '자동차', '전자장비와기기', '제약', '철강', '컴퓨터와주변기기', '항공사']\n",
        "category_list_us = ['건설 및 엔지니어링', '담배', '방송', '백화점', '사무기기', '손해보험', '식품 소매 및 유통', '항공우주 및 방위', '은행',\n",
        "                    '자동차 및 트럭 제조', '전자 장비 및 부품', '제약', '철 및 강철', '컴퓨터 하드웨어', '항공사']\n",
        "\n",
        "time_series_simularity = list()\n",
        "\n",
        "fig, axes = plt.subplots(5,3)\n",
        "fig.set_size_inches((20, 15))\n",
        "\n",
        "for i in range(len(category_list_kor)):\n",
        "  condition = data_n_kor['업종'] == category_list_kor[i]\n",
        "  condition_2 = data_n_us['업종'] == category_list_us[i]\n",
        "\n",
        "  data_n_kor_2 = data_n_kor.loc[condition]\n",
        "  data_n_kor_3 = data_n_kor_2.iloc[:,2:]\n",
        "\n",
        "  data_n_us_2 = data_n_us.loc[condition_2]\n",
        "  data_n_us_3 = data_n_us_2.iloc[:,2:]\n",
        "\n",
        "  array_value_kr = np.array(data_n_kor_3.iloc[0])\n",
        "  array_value_us = np.array(data_n_us_3.iloc[0])\n",
        "\n",
        "  distance = np.linalg.norm(array_value_kr-array_value_us)\n",
        "  time_series_simularity.append(distance)\n",
        "\n",
        "  axes[i//3, i%3].plot(array_value_kr)\n",
        "  axes[i//3, i%3].plot(array_value_us)\n",
        "\n",
        "  print(time_series_simularity) # 유사도 출력"
      ],
      "metadata": {
        "id": "kJIzXbQyD3x5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}